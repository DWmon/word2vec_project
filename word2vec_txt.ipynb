{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter, Kkma\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from copy import deepcopy\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "t=Twitter()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TXT_PATH = './txt2/'\n",
    "SAVE_PATH='./korea_wv/'\n",
    "\n",
    "def get_filelist(path):\n",
    "    filelist=[]\n",
    "    files = os.listdir(TXT_PATH) # txt파일에 있는 파일 리스트를 가져옴\n",
    "    for file in files:\n",
    "        ext = os.path.splitext(file)[-1]\n",
    "            \n",
    "        if ext == '.txt':\n",
    "            filelist.append(\"%s%s\" % (path, file))\n",
    "    return filelist\n",
    "\n",
    "\n",
    "def open_file(file):\n",
    "    txt_file = open(file, encoding='utf-8')\n",
    "    content = txt_file.read()\n",
    "    txt_file.close()\n",
    "    return content\n",
    "\n",
    "def preprocessing(content):\n",
    "    content = re.sub('\\\\xa0', '', content)\n",
    "    content = re.sub('\\\\n', '', content)\n",
    "    content = re.sub('\\\\\\\\xa0', '', content)\n",
    "    content = re.sub('\\\\\\\\n', '', content)\n",
    "    content = re.sub('[\\{\\}\\[\\]\\/?.,;:|\\)*~`!^\\-_+<>@#$%&\\\\\\=\\(\\'\\\")]', '', content)\n",
    "    content = ' '.join(content.split())\n",
    "                     \n",
    "    return content\n",
    "\n",
    "def wv_update(file):\n",
    "    new_token=[]\n",
    "    content.append(preprocessing(open_file(TXT_PATH+file)))\n",
    "    \n",
    "    \n",
    "    new_token=[tokenize(d) for d in content]\n",
    "    \n",
    "    wv_model_ko.build_vocab(new_token, update=True)\n",
    "    wv_model_ko.train(new_token, total_examples=wv_model_ko.corpus_count, epochs=wv_model_ko.epochs)\n",
    "    wv_model_ko.init_sims(replace=True)\n",
    "    now=datetime.now()\n",
    "    wv_model_ko.save('%s%s%s%s%s%s' % (SAVE_PATH, now.year, now.month, now.day, now.hour, now.minute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist=get_filelist(TXT_PATH)\n",
    "len(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def tokenize(doc):\n",
    "    return ['/'.join(t) for t in t.pos(doc, norm=True, stem=True)]\n",
    "\n",
    "content=[]\n",
    "for file in filelist:\n",
    "    content.append(preprocessing(open_file(file))) #content리스트 하나에 하나의 논문\n",
    "\n",
    "sentences = [tokenize(d) for d in content]  #논문 하나가 한 리스트에 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "wv_model_ko = Word2Vec(sentences, size=100, window = 8, min_count=10, workers=4, iter=100, sg=1)\n",
    "#100차원 벡터, 주변단어 2개 참조, 출연빈도 20번이상, CPU 쿼드코어, 100번 반복, CBOW, Skip-Gram중 후자\n",
    "now=datetime.now()\n",
    "wv_model_ko.save('%s%s%s%s%s%s' % (SAVE_PATH, now.year, now.month, now.day, now.hour, now.minute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_model_ko.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(wv_model_ko.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_model_ko.wv[tokenize('사전')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wv_model_ko.wv.most_similar(tokenize('엄마'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_model_ko.wv.similarity(*tokenize('소설 문학'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wv_model_ko.predict_output_word(tokenize('프로테오믹스'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager, rc\n",
    "font_fname='c:/windows/fonts/H2GTRM.TTF'\n",
    "font_name=font_manager.FontProperties(fname=font_fname).get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None \n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def tsne_plot(model):\n",
    "    \"Creates and TSNE model and plots it\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for word in model.wv.vocab:\n",
    "        tokens.append(model[word])\n",
    "        labels.append(word)\n",
    "    \n",
    "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(16, 16)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tsne_plot(wv_model_ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non=open('./txt/생식생물학에서_프로테오믹스의_응용.txt', encoding='utf-8').read()\n",
    "\n",
    "content2=[]\n",
    "\n",
    "content2.append(preprocessing(non)) #content리스트 하나에 하나의 논문\n",
    "\n",
    "non_ko = [tokenize(d) for d in content2]  #논문 하나가 한 리스트에 토큰화\n",
    "\n",
    "non_ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
